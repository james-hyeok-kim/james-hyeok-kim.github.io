<!DOCTYPE html>
<html lang="en">
<!-- Beautiful Jekyll 6.0.1 | Copyright Dean Attali 2023 -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

  

  

  <title>[논문리뷰]Fast Inference from Transformers via Speculative Decoding | AI 리부팅 (AI Rebooting)</title>

  
  
  <meta name="author" content="James Kim">
  

  <meta name="description" content="Speculative Decoding">

  

  

  
  <link rel="alternate" type="application/rss+xml" title="AI 리부팅 (AI Rebooting)" href="/feed.xml">
  

  

  

  

  

  
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script"></script>



  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/beautifuljekyll.css">
    
  

  

  
  
  

  

  
  <meta property="og:site_name" content="AI 리부팅 (AI Rebooting)">
  <meta property="og:title" content="[논문리뷰]Fast Inference from Transformers via Speculative Decoding | AI 리부팅 (AI Rebooting)">
  <meta property="og:description" content="Speculative Decoding">

  
  <meta property="og:image" content="/assets/img/AI.jpg">
  

  
  <meta property="og:type" content="article">
  
  <meta property="og:article:author" content="James Kim">
  
  <meta property="og:article:published_time" content="2025-08-21T00:00:00-04:00">
  <meta property="og:url" content="/2025-08-21-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-Fast-Inference-from-Transformers-via-Speculative-Decoding/">
  <link rel="canonical" href="/2025-08-21-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-Fast-Inference-from-Transformers-via-Speculative-Decoding/">
  

  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  <meta property="twitter:title" content="[논문리뷰]Fast Inference from Transformers via Speculative Decoding | AI 리부팅 (AI Rebooting)">
  <meta property="twitter:description" content="Speculative Decoding">

  
  <meta name="twitter:image" content="/assets/img/AI.jpg">
  

  


  

  
  

  

</head>


<body>
  


  <nav class="navbar navbar-expand-xl navbar-light fixed-top navbar-custom top-nav-regular"><a class="navbar-brand" href="/">AI 리부팅 (AI Rebooting)</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/about%20me">About Me</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://www.linkedin.com/in/jameskim525">Author's home</a>
          </li>
        <li class="nav-item">
          <a class="nav-link" id="nav-search-link" href="#" title="Search">
            <span id="nav-search-icon" class="fa fa-search"></span>
            <span id="nav-search-text">Search</span>
          </a>
        </li></ul>
  </div>

  

  
    <div class="avatar-container">
      <div class="avatar-img-border">
        <a href="/">
          <img alt="Navigation bar avatar" class="avatar-img" src="/assets/img/AI.jpg" />
        </a>
      </div>
    </div>
  

</nav>



<div id="beautifuljekyll-search-overlay">

  <div id="nav-search-exit" title="Exit search">✕</div>
  <input type="text" id="nav-search-input" placeholder="Search">
  <ul id="search-results-container"></ul>
  
  <script src="https://unpkg.com/simple-jekyll-search@latest/dest/simple-jekyll-search.min.js"></script>
  <script>
    SimpleJekyllSearch({
      searchInput: document.getElementById('nav-search-input'),
      resultsContainer: document.getElementById('search-results-container'),
      json: '/assets/data/searchcorpus.json' 
    });
  </script>
</div>





  



<header class="header-section ">
<div class="intro-header ">
  
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="post-heading">
          <h1>[논문리뷰]Fast Inference from Transformers via Speculative Decoding</h1>
          
            
              <h2 class="post-subheading">Speculative Decoding</h2>
            
          
          
           
            
              By <strong>James Kim</strong><br>
            
            <span class="post-meta">Posted on August 21, 2025</span>
            
            
          
        </div>
      </div>
    </div>
  </div>
  
  
</div>



</header>


<main class=" container-md ">
  <div class="row">
    <div class=" col-xl-8 offset-xl-2 col-lg-10 offset-lg-1 ">

      
        
        
        

        <div id="header-gh-btns">
          
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=james-hyeok-kim&repo=james-hyeok-kim.github.io.git&type=star&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=james-hyeok-kim&repo=james-hyeok-kim.github.io.git&type=fork&count=true" frameborder="0" scrolling="0" width="120px" height="20px"></iframe>
                
            
              
                  <iframe src="https://ghbtns.com/github-btn.html?user=james-hyeok-kim&type=follow&count=true" frameborder="0" scrolling="0" width="220px" height="20px"></iframe>
              
            
          
        </div>
      

      

      <div class="blog-post">
        <h1 id="speculative-decoding">Speculative Decoding</h1>

<h2 id="fast-inference-from-transformers-via-speculative-decoding">Fast Inference from Transformers via Speculative Decoding</h2>

<p>저자 : Yaniv Leviathan * 1 Matan Kalman * 1 Yossi Matias 1</p>

<p>출간 : ICML(International Conference on Machine Learning), 2023.</p>

<p>논문 : <a href="https://arxiv.org/pdf/2211.17192">PDF</a></p>

<hr />
<h3 id="background">Background</h3>
<ul>
  <li>GPT, T5, LaMDA 같은 Autoregressive Transformer 모델은 문장을 생성할 때 한 토큰씩 순차적으로 생성</li>
  <li>예를 들어 100개의 단어를 생성하려면, 모델을 100번 호출</li>
</ul>

<hr />

<h3 id="introduction">Introduction</h3>

<p>아이디어 요약</p>

<ol>
  <li>
    <p>작고 빠른 모델 (Mq) 을 먼저 사용해서 여러 개의 다음 토큰을 “추측”합니다.</p>
  </li>
  <li>
    <p>큰 모델 (Mp) 을 병렬로 실행해 이 추측들이 맞는지 검증합니다.</p>
  </li>
  <li>
    <p>맞으면 그 추측을 받아들이고, 틀리면 다시 샘플링합니다.</p>
  </li>
  <li>
    <p>이 과정을 통해 한 번에 최대 𝛾+1개의 토큰을 생성할 수 있습니다.</p>
  </li>
</ol>

<p>✅ 핵심: 모델의 출력을 바꾸지 않으면서, 속도만 빠르게 합니다!</p>

<p>(= 원래 Mp 단독으로 생성했을 때와 동일한 분포의 결과를 얻음)</p>

<hr />

<h3 id="algorithm">Algorithm</h3>

<h4 id="주요-모델-정의">주요 모델 정의</h4>
<ul>
  <li>
    <p>$𝑀_𝑝$: 원래 느리지만 정확한 대형 모델</p>
  </li>
  <li>
    <p>$𝑀_𝑞$ : 빠르고 작은 근사 모델</p>
  </li>
  <li>
    <p>$𝛾$ : 한 번에 몇 개의 토큰을 추측할지 결정하는 하이퍼파라미터</p>
  </li>
</ul>

<h4 id="알고리즘-흐름">알고리즘 흐름</h4>
<ol>
  <li>
    <p>$𝑀_𝑞$ 로 $𝛾$ 개의 토큰을 차례로 생성 (예: “나는”, “오늘”, “학교에”)</p>
  </li>
  <li>
    <p>$𝑀_𝑝$ 를 동시에 병렬로 실행해서 해당 토큰들의 확률을 평가함</p>
  </li>
  <li>
    <p>추측한 토큰들이 $𝑀_𝑝$ 기준으로도 괜찮다면 → 채택</p>

    <p>3-1. 그렇지 않으면 해당 지점부터 다시 샘플링</p>
  </li>
  <li>
    <p>최종적으로 한 번에 1개에서 최대 $𝛾+1$ 개의 토큰을 생성함</p>
  </li>
</ol>

<h4 id="시각적-예시">시각적 예시</h4>
<ul>
  <li>(논문 Figure 1 기반): 단계	추측 ($M_q$)	검증 ($M_p$)	결과</li>
</ul>

<p>1	“나는”, “오늘”, “학교에”	확인함	모두 통과 → 3개 수용</p>

<p>2	“간다”, “그리고”, “밥을”	2번째 틀림 → 1개만 수용</p>

<p>이런 식으로 병렬성 증가 + 확률 보존을 동시에 만족하는 구조입니다.</p>

<hr />

<h3 id="speculatvie-sampling">Speculatvie Sampling</h3>

<p>작은 모델 Mq의 제안을 가지고 큰 모델 Mp가 그 제안을 확률적으로 수용하거나 거절</p>

<h4 id="과정">과정</h4>
<ol>
  <li>
    <p>작은 모델 $𝑀_𝑞$ 에서 $𝑥∼𝑞(𝑥)$ 라는 샘플을 하나 뽑아</p>
  </li>
  <li>
    <p>이 샘플을 수용할지 말지 결정하기 위해, 큰 모델 $M_p$ 의 확률 분포 $𝑝(𝑥)$와 비교</p>
  </li>
</ol>

<h4 id="수용-조건">수용 조건</h4>
<ul>
  <li>
    <p>$𝑞(𝑥)≤𝑝(𝑥)$ 이면 그냥 수용!</p>
  </li>
  <li>
    <p>$𝑞(𝑥)&gt;𝑝(𝑥)$ 이면 확률적으로 거절할 수도 있음:</p>
    <ul>
      <li>거절 확률: $1−\frac{𝑝(𝑥)}{𝑞(𝑥)}$ 이 경우, 다시 샘플링을 진행해야 해요.</li>
    </ul>
  </li>
</ul>

<p>이 방법은 <strong>Rejection Sampling (거절 샘플링)</strong>의 일반화된 형태이면서, 동시에 효율을 크게 개선한 버전이에요.</p>

<h4 id="정당성">정당성</h4>
<p>논문 부록 A.1에서는 이렇게 증명</p>

<h5 id="변수-정의">변수 정의</h5>
<ul>
  <li>
    <p>$𝑝(𝑥)$ : 큰 모델이 주는 실제 분포</p>
  </li>
  <li>
    <p>$𝑞(𝑥)$ : 작은 모델이 주는 제안 분포</p>
  </li>
  <li>
    <p>$𝑥′$ : 어떤 특정 토큰 (예: “학교에”)</p>
  </li>
  <li>
    <p>특정 토큰 $𝑥′$ 이 선택될 확률 $𝑃(𝑥=𝑥′)$</p>
  </li>
</ul>

<h5 id="수용된-경우">수용된 경우</h5>

\[P_{수용}(x=x′)=min(p(x′),q(x′))\]

<ul>
  <li>$𝑞(𝑥′)&lt;𝑝(𝑥′)$ : 수용 확률 = $𝑞(𝑥′)$</li>
  <li>$𝑞(𝑥′)&gt;𝑝(𝑥′)$ : 수용 확률 = $𝑝(𝑥′)$</li>
  <li>때문에 $min(p(x′),q(x′))$으로 표현 가능</li>
</ul>

<h5 id="거절된-경우">거절된 경우</h5>

\[P_{거절 후 선택}(x=x′)=p(x′)−min(p(x′),q(x′))\]

<ul>
  <li>거절 후 다시 샘플링</li>
</ul>

<h5 id="전체-확률">전체 확률</h5>
<p>\(P(x=x′) = min(p(x′),q(x′)) + p(x′)−min(p(x′),q(x′)) = p(x′)\)</p>
<ul>
  <li>수용될 확률 + 거절 후 다시 뽑힐 확률</li>
</ul>

<hr />

<h3 id="speculative-decoding-algorithm-1">Speculative Decoding Algorithm 1</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Inputs</span><span class="p">:</span> <span class="n">Mp</span><span class="p">,</span> <span class="n">Mq</span><span class="p">,</span> <span class="n">prefix</span>

<span class="c1"># 1. 작은 모델로 γ개 토큰 추측
</span><span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="n">to</span> <span class="n">γ</span><span class="p">:</span>
    <span class="n">xi</span> <span class="o">~</span> <span class="nc">Mq</span><span class="p">(</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">x1</span> <span class="o">+</span> <span class="p">...</span> <span class="o">+</span> <span class="n">xi</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 2. 큰 모델로 prefix들에 대해 동시에 평가
</span><span class="n">p1</span><span class="p">,</span> <span class="p">...,</span> <span class="n">pγ</span><span class="o">+</span><span class="mi">1</span> <span class="o">~</span> <span class="nc">Mp</span><span class="p">(</span><span class="n">prefix</span><span class="p">),</span> <span class="nc">Mp</span><span class="p">(</span><span class="n">prefix</span><span class="o">+</span><span class="n">x1</span><span class="p">),</span> <span class="p">...,</span> <span class="nc">Mp</span><span class="p">(</span><span class="n">prefix</span><span class="o">+</span><span class="n">x1</span><span class="o">+</span><span class="p">...</span><span class="o">+</span><span class="n">xγ</span><span class="p">)</span>

<span class="c1"># 3. 수용 여부 판단
</span><span class="n">n</span> <span class="o">=</span> <span class="n">가장</span> <span class="n">먼저</span> <span class="n">수용</span> <span class="n">실패하는</span> <span class="n">위치</span>

<span class="c1"># 4. 다시 샘플링 (보정)
</span><span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">γ</span><span class="p">:</span>
    <span class="n">p</span><span class="err">′</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="nf">norm</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pn</span><span class="o">+</span><span class="mi">1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">qn</span><span class="o">+</span><span class="mi">1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">p</span><span class="err">′</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">pn</span><span class="o">+</span><span class="mi">1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 5. 최종 토큰 t ~ p′(x)
</span><span class="k">return</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="p">...,</span> <span class="n">xn</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>
</code></pre></div></div>

<hr />

<h3 id="성능-분석">성능 분석</h3>
<ol>
  <li>
    <p>한 번의 실행에서 평균적으로 몇 개의 토큰을 생성할 수 있는가?</p>
  </li>
  <li>
    <p>전체 디코딩 시간(walltime)이 얼마나 줄어드는가?</p>
  </li>
  <li>
    <p>전체 연산량(arithmetic operations)은 얼마나 증가 또는 감소하는가?</p>
  </li>
</ol>

<h4 id="31-생성되는-토큰-수-e-tokens">3.1. 생성되는 토큰 수 (E[# tokens])</h4>
<h4 id="정의-수용률-𝛽">정의: 수용률 𝛽</h4>

<ul>
  <li>특정 prefix $𝑥&lt;𝑡$에 대해, 작은 모델 $𝑀_𝑞$ 의 예측을 큰 모델 $𝑀_𝑝$이 수용할 확률</li>
</ul>

\[𝛽=𝐸_{𝑥∼𝑞(𝑥)}[min⁡(1,\frac{𝑝(𝑥)}{𝑞(𝑥)})]=\displaystyle\sum_x min⁡(𝑝(𝑥),𝑞(𝑥))\]

<ul>
  <li>
    <p>이 값이 높을수록 작은 모델이 큰 모델을 더 잘 근사한다는 뜻</p>
  </li>
  <li>
    <p>평균 수용률을 𝛼 =𝐸[𝛽]라고 정의</p>
  </li>
</ul>

<h4 id="기대-생성-토큰-수-γ1개까지-가능">기대 생성 토큰 수 (γ+1개까지 가능)</h4>
<ul>
  <li>한 번의 Algorithm 1 실행에서 평균적으로 생성되는 토큰 수는 다음과 같습니다:</li>
</ul>

\[𝐸[tokens] = \frac{1−𝛼^{𝛾+1}}{1−𝛼}\]

<ul>
  <li>예시
$𝛼=0.8, 𝛾=3$
\(𝐸[tokens]=\frac{1−0.8^{4}}{1−0.8} = \frac{1−0.4096}{0.2}=2.95\)</li>
</ul>

<p>즉, 평균적으로 거의 3개 생성 (원래는 1개씩만 가능했음)</p>

<ul>
  <li>
    <p>𝛾개 토근 제안하고, 하나라도 틀리면 멈추기 때문에 평균 수용률  $\alpha$는 아래 공식으로 유도</p>
  </li>
  <li>
    <p>수용된 토큰 수 𝑛은 다음을 따릅니다:</p>
  </li>
</ul>

<p>\(𝑃(𝑛=𝑘)=𝛼^𝑘(1−𝛼), \ \ \ for \ 𝑘&lt;𝛾\)
\(𝑃(𝑛=𝛾)=𝛼^{𝛾}\)</p>

<ul>
  <li>즉,γ번 연속 수용되면 멈추지 않고, 그 다음 토큰도 하나 더 만듭니다.
→ n+1, 즉 최대 𝛾+1</li>
</ul>

<p>그래서 기대값은</p>

\[𝐸[tokens]=\displaystyle\sum_{𝑘=0}^{𝛾−1}(𝑘+1)𝛼^𝑘(1−𝛼)+(𝛾+1)𝛼^𝛾\]

<p>(등비수열의 합공식)</p>

\[E[tokens]= \frac{1−α^{γ+1}}{1−α}\]

<h4 id="32-walltime-개선">3.2. Walltime 개선</h4>
<ul>
  <li>변수 정의</li>
</ul>

<p>c: 작은 모델 한 번 실행 시간 / 큰 모델 한 번 실행 시간 비율</p>

<p>(예: T5-small은 T5-XXL보다 훨씬 빠르니 𝑐≪1)</p>

<h4 id="기대-속도-개선-비율">기대 속도 개선 비율:</h4>

\[Improvement = \frac{1−α^{γ+1}}{(1−α)(γc+1)}\]

<ul>
  <li>
    <p>α: 수용률 (작은 모델의 제안이 큰 모델에 의해 받아들여질 확률)</p>
  </li>
  <li>
    <p>γ: 추측하는 토큰 수</p>
  </li>
  <li>
    <p>c: 작은 모델(Mq)의 실행 시간 / 큰 모델(Mp)의 실행 시간 비율</p>
  </li>
  <li>
    <p>γc: 작은 모델을 γ번 실행하는 데 드는 시간</p>
  </li>
  <li>
    <p>+1: 큰 모델을 한 번 실행하는 데 드는 시간</p>
  </li>
</ul>

<h5 id="예시">예시</h5>
<ul>
  <li>α=0.75, γ=7, c=0.02</li>
</ul>

\[Improvement ≈ \frac{1−0.75^{8}}{(1−0.75)(0.14+1)} ≈ \frac{0.9}{0.25 \odot 1.14} ≈ 3.16x\]

<h3 id="33-전체-연산량-arithmetic-operations">3.3. 전체 연산량 (Arithmetic Operations)</h3>
<p>병렬성은 증가했지만, 계산량은 줄어들 수도 있고, 오히려 늘어날 수도 있습니다.</p>

<h4 id="기대-연산량-증가-비율">기대 연산량 증가 비율:</h4>

\[Ops \ Increase = \frac{(1−α)(γ \hat{c}+γ+1)}{1-α^{γ+1}}\]

<p>(한 토큰당 연산량 with Algorithm 1)÷(기존 Mp에서 한 토큰당 연산량)</p>

<p>​
$\hat{c}$ : 작은 모델의 연산량 / 큰 모델의 연산량 비율</p>

<p>→ 이 값이 1보다 크면 연산량은 늘어나지만, walltime은 줄어듦</p>

<p>→ 실전에서는 메모리 대역폭이 병목이기 때문에 이 손해는 감수할 만함</p>

<h3 id="34-γ-값-선택-성능-vs-비용-최적화">3.4. γ 값 선택 (성능 vs 비용 최적화)</h3>
<ul>
  <li>
    <p>γ가 너무 작으면 병렬 효과가 적고,</p>
  </li>
  <li>
    <p>γ가 너무 크면 연산 낭비가 많음</p>
  </li>
</ul>

<p>논문에서는 γ에 따라 벽시간 개선량이 볼록 함수 형태로 존재함을 수치적으로 보여줍니다.</p>

      </div>

      
        <div class="blog-tags">
          <span>Tags:</span>
          
            <a href="/tags#test">test</a>
          
        </div>
      

      

      
        <!-- Check if any share-links are active -->




<section id = "social-share-section">
  <span class="sr-only">Share: </span>

  

  

  
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=%2F2025-08-21-%25EB%2585%25BC%25EB%25AC%25B8%25EB%25A6%25AC%25EB%25B7%25B0-Fast-Inference-from-Transformers-via-Speculative-Decoding%2F"
      class="btn btn-social-icon btn-linkedin" title="Share on LinkedIn">
      <span class="fab fa-fw fa-linkedin" aria-hidden="true"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  

  

  

</section>



      

      <ul class="pagination blog-pager">
        
        <li class="page-item previous">
          <a class="page-link" href="/2025-08-21-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-Denoising-Diffusion-Probabilistic-Models(DDPM)/" data-toggle="tooltip" data-placement="top" title="[논문리뷰]Denoising Diffusion Probabilistic Models(DDPM)">
            <i class="fas fa-arrow-left" alt="Previous Post"></i>
            <span class="d-none d-sm-inline-block">Previous Post</span>
          </a>
        </li>
        
        
        <li class="page-item next">
          <a class="page-link" href="/2025-08-21-Activation_function/" data-toggle="tooltip" data-placement="top" title="Activation function (Non-linear)">
            <span class="d-none d-sm-inline-block">Next Post</span>
            <i class="fas fa-arrow-right" alt="Next Post"></i>
          </a>
        </li>
        
      </ul>
      
  
  
  

  


  

  



    </div>
  </div>
</main>


  <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      
<ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="mailto:younghyeok25@gmail.com" title="Email me">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">Email me</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/https://github.com/james-hyeok-kim/james-hyeok-kim.github.io.git" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li><li class="list-inline-item">
    <a href="https://linkedin.com/in/https://www.linkedin.com/in/jameskim525" title="LinkedIn">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">LinkedIn</span>
   </a>
  </li></ul>


      
      <p class="copyright text-muted">
      
        James kim
        &nbsp;&bull;&nbsp;
      
      2025

      
        &nbsp;&bull;&nbsp;
        <span class="author-site">
          <a href="/">MyWebsite.com</a>
        </span>
      

      

      

      </p>
      <p class="theme-by text-muted">
        Powered by
        <a href="https://beautifuljekyll.com">Beautiful Jekyll</a>
      </p>
      </div>
    </div>
  </div>
</footer>


  
  
    
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/beautifuljekyll.js"></script>
    
  









</body>
</html>
