# Normalization Techniques 

## Batch & Channel & Layer Normalization
<P align="center">
<img src="https://github.com/user-attachments/assets/cd06d0d0-44ab-4d6c-b1e3-9fdf046b4e83" width="60%" height="60%">
</P>

$$y = \frac{(x - mean)}{\sqrt{(var + eps)}}$$

## RMS Normalization
* Root Mean Square Layer Normalization

$$y=\frac{x}{\sqrt{(mean(xÂ²)+Îµ)}}$$


|êµ¬ë¶„|Layer Normalization|RMSNorm|
|:---:|:---:|:---:|
|ì •ê·œí™” ë°©ì‹|	í‰ê· ê³¼ ë¶„ì‚°ì„ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”|	ì œê³±í‰ê· ì„ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”|
|ê³„ì‚° ë¹„ìš©|	í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°,ë¹„ìš©ì´ ë” ë†’ìŒ|	ì œê³±í‰ê·  ê³„ì‚°ë§Œ, ë¹„ìš©ì´ ë” ë‚®ìŒ|
|íŒŒë¼ë¯¸í„°|	ğ›¾ (ìŠ¤ì¼€ì¼ íŒŒë¼ë¯¸í„°), ğ›½ (ì‹œí”„íŠ¸ íŒŒë¼ë¯¸í„°)|	ğ›¾ (ìŠ¤ì¼€ì¼ íŒŒë¼ë¯¸í„°)|
|ë°°ì¹˜| ë¯¼ê°ë„	ë¯¼ê°í•˜ì§€ ì•ŠìŒ|	ë¯¼ê°í•˜ì§€ ì•ŠìŒ|
|ì£¼ ì‚¬ìš© ì‚¬ë¡€|	RNNê³¼ ê°™ì€ ìˆœí™˜ ì‹ ê²½ë§	|ëŒ€ê·œëª¨ ì‹ ê²½ë§, ê³„ì‚° ë¹„ìš©ì´ ë‚®ì€ ëª¨ë¸ (transformer)|
|ì¥ì |	ê° ìƒ˜í”Œì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ ê³ ë ¤, ì •ê·œí™”, ì•ˆì •ì ì¸ í•™ìŠµ ê°€ëŠ¥|	ê³„ì‚° ë¹„ìš©ì´ ë‚®ê³  ê°„ë‹¨í•œ ê³„ì‚° ì •ê·œí™”|
|ë‹¨ì |	í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°ìœ¼ë¡œ ì¸í•´ ê³„ì‚° ë¹„ìš©ì´ ë†’ìŒ|	í‰ê· ì„ ê³ ë ¤í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì¼ë¶€ ê²½ìš°ì—ì„œ í•™ìŠµ ì•ˆì •ì„± ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ|

# Standardization Techniques


## Data standardization


## Z-score standardization


## AdaNorm $\Phi(y)$
1. $\Phi(y)$ ë¯¸ë¶„ ê°€ëŠ¥
2. í‰ê·  scaling wiehgt ê³ ì •(fixed)
3. z í‰ê·  bounded(íŠ¹ì • ë²”ìœ„)

$$ \Phi(y_i) = C(1-\frac{y_i}{10}) $$

$$ z=C(1-ky)\odot y, y=\frac{x-\mu}{\sigma}, \mu = \frac{1}{H} \displaystyle\sum^H_{i=1}x_i, \sigma = \sqrt{\frac{1}{H}\displaystyle\sum_{i=1}^{H}(x_i - \mu)^2}$$ 

* $C = hyper parameter, k = 1/10$


# Adaptive Instance Normalization
Content Input $x$, Style Input $y$
* Simply align the channel-wise mean and variance of x to match those of y
* AdaIN has no learnable affine parameters.

$$ AdaIN(x,y) = \sigma(y)\left(\frac{x-\mu(x)}{\sigma(x)}\right) + \mu(y) $$


# Normalization

* Training Parameter

$$ \hat{x_i} = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}} $$ 
$$ y_i = \gamma\hat{x} + \beta $$
$$ \gamma = scale, \beta = shift, Both \ training \ parameter $$

* Variance

$$ \sigma^2 = \frac{1}{m}\displaystyle\sum_{i=1}^{m}(x_i-\mu)^2 $$  
$$ \sigma^2 = \frac{\sum(x^2)}{N} - \left(\frac{\sum(x)}{N}\right)^2 $$

* Standard Deviation

$$ \sigma = \sqrt{\frac{1}{m}\displaystyle\sum_{i=1}^{m}(x_i-\mu)^2} $$ 
$$ \sigma = \sqrt{\frac{\sum(x^2)}{N} - \left(\frac{\sum(x)}{N}\right)^2} $$
